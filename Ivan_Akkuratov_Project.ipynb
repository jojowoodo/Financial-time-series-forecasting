{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Financial time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following project is could be done individually or in pairs but you not allowed to share your solution with anyone else. Read below carefully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The aim of the project is that you learn how to set up an analytics project end-to-end. A secondary aim is that you understand how to work with a time series data set and forecast based on such data. Third aim is that you gain an insight into how to interpret data and results.\n",
    "\n",
    "- The solution must address each grade in the written order. Therefore, to complete grade five you must have completed the other grades first.\n",
    "\n",
    "- Unintentionally, there may be information missing in the description, please go through the description early in advance so that you have time to ask for assistance.\n",
    "\n",
    "- Make sure to rewrite your code as functions where you can\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First upgrade the environment.\n",
    "# https://pypi.org/project/yfinance\n",
    "import pip\n",
    "from subprocess import run\n",
    "# add what you will need\n",
    "modules =[\n",
    "#     'pandas_datareader',\n",
    "#     'yfinance',\n",
    "    'pandas_market_calendars',\n",
    "    'plotly', \n",
    "    'numpy',\n",
    "    'sklearn',\n",
    "    'pandas'\n",
    "]\n",
    "proc = run(f'pip install {\" \".join(modules)} --upgrade --no-input', \n",
    "       shell=True, \n",
    "       text=True, \n",
    "       capture_output=True, \n",
    "       timeout=40)\n",
    "print(proc.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FuncFormatter, StrMethodFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly as ply\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from pprint import PrettyPrinter\n",
    "pprint = PrettyPrinter().pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='g1'></a>\n",
    "# Grade 1\n",
    "## Implement a complete process for forecasting a single stock.\n",
    "\n",
    "You should do the following steps:\n",
    "- Use the [EURUSD data set](https://people.arcada.fi/~parland/hjd5_8amp_Gt3/EURUSD1m.zip) (52Mb)\n",
    "- Subsampe data to one day timesteps(remember to use .agg())\n",
    "- Create a label column for your forecast, by shifting the Close value 1 step. You will predict one day ahead,  insert the new column into a new dataframe or the existing one\n",
    "- Split data into 80/20 (train/test). Be carefull: you are splitting a time serie\n",
    "- [Normalize or standardize](https://scikit-learn.org/stable/modules/preprocessing.html) wisely so you don't allow information leakage from the test subset\n",
    "- Calculate feature [Larry William’s %R](https://www.investopedia.com/terms/w/williamsr.asp) from the paper [Predicting the Direction of Stock Market Index Movement Using an Optimized Artificial Neural Network Model]\n",
    "(https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4873195) (implement in code, insert values in complementary columns). Note that you need to implement your own calculation of each feature and be able to explain the code.\n",
    "- You can use something like this to understand Larry williams %R better: https://school.stockcharts.com/doku.php?id=technical_indicators:williams_r\n",
    "- Drop other data than the Close and the features for inference. You don't want to feed time-column into the model, it's not a feature to base prediction on.\n",
    "- Set up a [linear model](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares) \n",
    "- Fit/train the linear model to the training data\n",
    "- Forecast 1 day ahead based on the test data and compare it to the closing values\n",
    "- Calculate the [R² error](https://en.wikipedia.org/wiki/Coefficient_of_determination) on both the training data set and the test. Please format numbers to four [significant digits](https://en.wikipedia.org/wiki/Significant_figures).\n",
    "- Compare the errors and explain the outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#downloading the data to a dataframe (Im not saving it locally though)\n",
    "df = pd.read_csv('https://people.arcada.fi/~parland/hjd5_9amp_Gt3/EURUSD1m.zip')\n",
    "\n",
    "\n",
    "#Converting the int64 to string\n",
    "df['NewDate'] = pd.to_datetime(df['Date'].astype(str), format='%Y%m%d')\n",
    "#Set the date as the index\n",
    "df = df.set_index(pd.DatetimeIndex(df['NewDate'].values))\n",
    "\n",
    "#Here i download the csv file and save it directly to a dataframe, convert the dates to a string, format them and \n",
    "#set them as a new row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create a new dataframe but grouped by days instead of minutes and aggregates the new rows\n",
    "df2Daily = (df.resample('D').agg({'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last','Volume':'sum'}))\n",
    "\n",
    "#Dropping rows with NaN\n",
    "df2Daily.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculating LWR\n",
    "period = 14\n",
    "df2Daily['LWR'] = ((df2Daily.High.rolling(period).max()-df2Daily.Close)/\n",
    "                   (df2Daily.High.rolling(period).max()-df2Daily.Low.rolling(period).min())*100)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#shifting Close row to the label row one day ahead\n",
    "df2Daily['Label'] = df2Daily['Close'].shift(-1)\n",
    "df2Daily.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Splitting the train and test data\n",
    "train, test = df2Daily[:int(len(df2Daily)*.8)], df2Daily[int(len(df2Daily)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the axises for linear regression\n",
    "X_train = train[['Close','LWR']]\n",
    "Y_train = train['Label']\n",
    "\n",
    "X_test = test[['Close','LWR']]\n",
    "Y_test = test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing x,y train values\n",
    "from sklearn import preprocessing\n",
    "Xscaler = preprocessing.StandardScaler()\n",
    "Yscaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_scaled = Xscaler.fit_transform(np.array(X_train))\n",
    "Y_scaled = Yscaler.fit_transform(np.array(Y_train).reshape(-1,1))\n",
    "\n",
    "X_scaledTest = Xscaler.transform(np.array(X_test))\n",
    "Y_scaledTest = Yscaler.transform(np.array(Y_test).reshape(-1,1))\n",
    "\n",
    "predictionArray = Xscaler.inverse_transform(X_scaledTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating linear regression predictor\n",
    "regressor = LinearRegression().fit(X_scaled,Y_scaled)\n",
    "\n",
    "#Inversing back the scaled values so they aren't minus\n",
    "#prediction = regressor.predict(Xscaler.inverse_transform(X_scaledTest))\n",
    "prediction = regressor.predict((predictionArray))\n",
    "\n",
    "#R2 using regressor.score\n",
    "print(\"Regression test Score: \",\"{0:.4}\".format( regressor.score(X_scaledTest,Y_scaledTest)))\n",
    "\n",
    "print(\"Regression Train score: \",\"{0:.4f}\".format(regressor.score(X_scaled, Y_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creationg a copy of the daily dataframe and later inserting a new prediction row\n",
    "DailyPredict = df2Daily.copy().tail(len(X_scaledTest))\n",
    "\n",
    "#Inserting the prediction array into the dataframe as a newcolumn\n",
    "DailyPredict['Prediction'] = prediction\n",
    "\n",
    "#Saving the new row in the dataframe \n",
    "DailyPredict['Prediction'] = DailyPredict['Prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I assume that the reason for as to why the R2 value is higher for the train score over the test score is because of test scores lower sample value vs train's sample value (623 vs 2491), thus having less datapoints to go after. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Larry William’s %R**\n",
    "\n",
    "$ (H_n − C_t)/(H_n − L_n)\\times100 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of determination ($R^2$)\n",
    "\n",
    "$$R^2 = 1 - \\frac {SSResid}{SSTot}$$\n",
    "\n",
    "#### Residual Sum of Squares: $SSResid = \\sum_{i} (y_i - \\hat{y_i})^2$\n",
    "\n",
    "#### Total Sum of Squares: $SSTot = \\sum_{i} (y_i - \\bar{y})^2$\n",
    "\n",
    "#### A baseline model, which always predicts $\\bar {y}$, will have $R^2 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='g2'></a>\n",
    "# Grade 2\n",
    "## Illustrate data using plotly (or other) library\n",
    "\n",
    "- Calculate additional feature [Stochastic slow %D](https://tradingsim.com/blog/slow-stochastics)\n",
    "- Create a figure based on OHLC candles covering the test period, you can re-use it from the past assignments\n",
    "- Second add a line chart(s) that illustrates the *label* (actual data) and the *forecast* in the same figure over OHLC. The lines should have different colors and include names of series.\n",
    "- Add subplot(s) with features so we can se them time-aligned\n",
    "- What patterns can you observe from the line figure?\n",
    "# found no errors in this description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic %K\t\n",
    "<br>\n",
    "<span style='font-size:20px'>\n",
    "$\\frac{(C_t − L_n)}{(H_n − L_n)}\\times100$\n",
    "</span>\n",
    "    \n",
    "### Stochastic %D\n",
    "<br>\n",
    "<span style='font-size:20px'>\n",
    "$\\sum\\nolimits_{i=0}^{n-1}\\frac{\\%K_{t-i}}n$\n",
    "</span>\n",
    "    \n",
    "### Stochastic slow %D\n",
    "<br>\n",
    "<span style='font-size:25px'>\n",
    "$\\frac{\\sum_{i=0}^{n-1}\\%D_{t-i}}n$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Periods\n",
    "period = 14\n",
    "shortPeriod = 3\n",
    "\n",
    "#Fast stochastic\n",
    "fastK = (DailyPredict['Close'] - DailyPredict['Low'].rolling(period).min())/(DailyPredict['High'].rolling(period).max() - DailyPredict['Low'].rolling(period).min()) * 100\n",
    "fastD = fastK.rolling(shortPeriod).mean()\n",
    "\n",
    "#Slow stochastic\n",
    "slowK = fastK.rolling(shortPeriod).mean()\n",
    "slowD = slowK.rolling(shortPeriod).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the different features\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#Creating the Euro to usd OHLC\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True, \n",
    "               vertical_spacing=0.03, subplot_titles=('EUR/USD', ''), \n",
    "               row_width=[0.4,0.4,0.9] )\n",
    "\n",
    "# Potting OHLC\n",
    "fig.add_trace(go.Candlestick(x=DailyPredict.index, open=DailyPredict[\"Open\"], high=DailyPredict[\"High\"],\n",
    "                low=DailyPredict[\"Low\"], close=DailyPredict[\"Close\"], name=\"EUR/USD\"), \n",
    "                row=1, col=1, )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "#fig.append_trace(go.Scatter(x=DailyPredict.index,y=slowD), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=slowD,line=dict(width=2, color='#5fad75'), name=\"Stochastic slow %D\"), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['LWR'],line=dict(width=2, color='#7d5a8c'), name=\"Larry William’s %R\"), row=3, col=1)\n",
    "\n",
    "\n",
    "# Bar trace for volumes on 2nd row without legend\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['Prediction'],line=dict(width=2, color='#FF00FF'), name=\"Prediction\"))\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['Close'],line=dict(width=2, color='#00FFFF'), name=\"Label\"))\n",
    "fig.update(layout_xaxis_rangeslider_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I notice that the dips in the stock price correlate with the same date on both Larry williams and stochastic slow %D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='g3'></a>\n",
    "# Grade 3\n",
    "\n",
    "- Calculate additional feature [RSI (relative strength index)](https://www.investopedia.com/terms/r/rsi.asp)\n",
    "- Add the feature as a subplot to the illustration from in the previos step\n",
    "- Set up an [ElasticNet](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net) model\n",
    "- Fit/train the ElasticNet to the training data\n",
    "- Forecast and calculate the R² error on both the training data set and the test\n",
    "- Combine line chart(s) that illustrates the *label* (actual data) and the *forecast* from both models in the previos figure.\n",
    "- Compare the errors and explain the outcome\n",
    "# Found no errors in this description either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSI\n",
    "<br>\n",
    "<span style='font-size:25px'>\n",
    "$100-\\frac{100}{\\left(1+\\frac{\\frac{\\sum_{i=0}^{n-1}Up_{t-i}}{\\text{n}}}{\\frac{\\sum_{i=0}^{n-1}Dw_{t-i}}{\\text{n}}}\\right)} $\n",
    "    </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating SMA\n",
    "def SMA(DailyPredict, period=14, column='Close'):\n",
    "    return DailyPredict[column].rolling(window=period).mean()\n",
    "\n",
    "\n",
    "#Calculating RSI\n",
    "def RSI(DailyPredict,period = 14, column='Close'):\n",
    "    delta = DailyPredict[column].diff(1)\n",
    "    delta = delta[1:]\n",
    "    up = delta.copy()\n",
    "    down = delta.copy()\n",
    "    up[up <0] = 0\n",
    "    down[down>0] = 0\n",
    "    DailyPredict['up'] = up\n",
    "    DailyPredict['down'] = down\n",
    "    AVG_Gain = SMA(DailyPredict, period, column = 'up')\n",
    "    AVG_Loss = abs(SMA(DailyPredict, period, column = 'down'))\n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0/(1.0+RS))\n",
    "        \n",
    "    return RSI\n",
    "\n",
    "#Inserting the RSI into the dataframe\n",
    "DailyPredict['RSI'] = RSI(DailyPredict)\n",
    "DailyPredict.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Graph with RSI\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#Creating the Eur to usd OHLC\n",
    "fig = make_subplots(rows=4, cols=1, shared_xaxes=True, \n",
    "               vertical_spacing=0.03, subplot_titles=('EUR/USD', ''), \n",
    "               row_width=[0.4,0.4,0.4,0.9] )\n",
    "\n",
    "#Potting OHLC\n",
    "fig.add_trace(go.Candlestick(x=DailyPredict.index, open=DailyPredict[\"Open\"], high=DailyPredict[\"High\"],\n",
    "                low=DailyPredict[\"Low\"], close=DailyPredict[\"Close\"], name=\"EUR/USD\"), \n",
    "                row=1, col=1, )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "#fig.append_trace(go.Scatter(x=DailyPredict.index,y=slowD), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=slowD,line=dict(width=2, color='#5fad75'), name=\"Stochastic slow %D\"), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['LWR'],line=dict(width=2, color='#7d5a8c'), name=\"Larry William’s %R\"), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['RSI'],line=dict(width=2, color='#2FAC9F'), name=\"RSI\"), row=4, col=1)\n",
    "\n",
    "#Bar trace for volumes on 2nd row without legend\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['Prediction'],line=dict(width=2, color='#FF00FF'), name=\"Prediction\"))\n",
    "fig.add_trace(go.Scatter(x=DailyPredict.index, y=DailyPredict['Label'],line=dict(width=2, color='#00FFFF'), name=\"Label\"))\n",
    "\n",
    "fig.update(layout_xaxis_rangeslider_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "best_lr_score = regressor.score(X_scaledTest,Y_scaledTest)\n",
    "best_d = 0\n",
    "best_a = 0\n",
    "best_r = 0\n",
    "for alpha in np.logspace(-19,-15,5):\n",
    "    for ratio in np.logspace(8,13,6):\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "        lr.fit(X_scaled, Y_scaled)\n",
    "        dif = lr.score(X_scaledTest, Y_scaledTest) - best_lr_score\n",
    "        if dif > best_d:\n",
    "            best_d = dif\n",
    "            best_a = alpha\n",
    "            best_r = ratio\n",
    "print(\"ElasticNet with Lwr and stochastic slow d\")\n",
    "print(f'{\"Best alpha\":<20}{best_a:.1e}')\n",
    "print(f'{\"Best l1_ratio\":<20}{best_r:.1e}')\n",
    "print(f'{\"Gain over LinearR\":<20}{best_d:.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
